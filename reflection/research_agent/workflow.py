"""Main workflow orchestration for the research agent."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any

import aisuite as ai

from .config import ResearchAgentConfig
from .llm import generate_draft, reflect_on_draft, revise_draft


@dataclass(slots=True)
class IterationResult:
    """Results from a single iteration of the workflow."""
    iteration: int
    essay_text: str
    feedback: str | None
    word_count: int
    
    @property
    def is_initial(self) -> bool:
        """Check if this is the initial draft (no feedback)."""
        return self.feedback is None


@dataclass(slots=True)
class WorkflowArtifacts:
    """Complete artifacts from the research agent workflow."""
    topic: str
    iterations: list[IterationResult]
    final_essay_path: Path | None = None
    feedback_path: Path | None = None
    
    @property
    def initial_draft(self) -> str:
        """Get the initial draft text."""
        return self.iterations[0].essay_text
    
    @property
    def final_essay(self) -> str:
        """Get the final essay text."""
        return self.iterations[-1].essay_text
    
    @property
    def total_iterations(self) -> int:
        """Get the total number of iterations."""
        return len(self.iterations)


def _count_words(text: str) -> int:
    """Count words in a text string."""
    return len(text.split())


def _check_convergence(previous_text: str, current_text: str) -> bool:
    """
    Check if the essay has converged (minimal changes).
    
    Args:
        previous_text: Previous iteration's essay
        current_text: Current iteration's essay
        
    Returns:
        True if converged (texts are very similar)
    """
    # Simple convergence check: if texts are identical or very similar
    if previous_text.strip() == current_text.strip():
        return True
    
    # Check if word count change is minimal (< 5%)
    prev_words = _count_words(previous_text)
    curr_words = _count_words(current_text)
    
    if prev_words > 0:
        change_ratio = abs(curr_words - prev_words) / prev_words
        if change_ratio < 0.05:  # Less than 5% change
            return True
    
    return False


def _build_feedback_markdown(
    *,
    topic: str,
    iterations: list[IterationResult],
    essay_basename: str,
) -> str:
    """Build a markdown file documenting all iterations and feedback."""
    lines = [
        f"# Essay Feedback: {essay_basename}",
        "",
        "## Topic",
        "",
        topic,
        "",
        "## Iterations",
        "",
    ]
    
    for iteration in iterations:
        lines.append(f"### Iteration {iteration.iteration}")
        lines.append("")
        lines.append(f"**Word Count:** {iteration.word_count}")
        lines.append("")
        
        if iteration.feedback:
            lines.append("**Feedback:**")
            lines.append("")
            lines.append(iteration.feedback)
            lines.append("")
        else:
            lines.append("**Feedback:** Initial draft (no reflection)")
            lines.append("")
        
        lines.append("---")
        lines.append("")
    
    # Add final summary
    final_iteration = iterations[-1]
    lines.extend([
        "## Final Essay",
        "",
        f"**Word Count:** {final_iteration.word_count}",
        f"**Total Iterations:** {len(iterations)}",
        "",
        "---",
        "",
        "*Generated by the Research Agent with Reflective Writing*",
    ])
    
    return "\n".join(lines)


def run_research_workflow(
    *,
    topic: str,
    config: ResearchAgentConfig,
    client: ai.Client | None = None,
) -> WorkflowArtifacts:
    """
    Execute the full reflective essay writing workflow.
    
    Args:
        topic: The essay topic or question
        config: Workflow configuration
        client: aisuite client (created if None)
        
    Returns:
        WorkflowArtifacts containing all iterations and outputs
    """
    # Initialize client if not provided
    if client is None:
        client = ai.Client()
    
    # Ensure output directory exists
    output_dir = config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    iterations: list[IterationResult] = []
    
    # Step 1: Generate initial draft
    draft_text = generate_draft(
        topic=topic,
        model=config.draft_model,
        temperature=config.draft_temperature,
        client=client,
    )
    
    iterations.append(
        IterationResult(
            iteration=1,
            essay_text=draft_text,
            feedback=None,
            word_count=_count_words(draft_text),
        )
    )
    
    previous_text = draft_text
    
    # Step 2+: Reflection and revision loop
    max_iters = max(1, config.max_iterations)
    
    for iteration_index in range(2, max_iters + 1):
        # Reflect on previous iteration
        feedback = reflect_on_draft(
            draft=previous_text,
            model=config.reflection_model,
            temperature=config.reflection_temperature,
            client=client,
        )
        
        # Check for convergence
        if config.stop_on_convergence and iteration_index > 2:
            # If feedback suggests no major changes needed, we might stop
            # This is a simple heuristic - could be enhanced
            if "no significant issues" in feedback.lower() or "excellent" in feedback.lower():
                break
        
        # Revise based on feedback
        revised_text = revise_draft(
            original_draft=previous_text,
            reflection=feedback,
            model=config.revision_model,
            temperature=config.revision_temperature,
            client=client,
        )
        
        # Check if text has converged
        if config.stop_on_convergence and _check_convergence(previous_text, revised_text):
            # Save this iteration but stop
            iterations.append(
                IterationResult(
                    iteration=iteration_index,
                    essay_text=revised_text,
                    feedback=feedback,
                    word_count=_count_words(revised_text),
                )
            )
            break
        
        iterations.append(
            IterationResult(
                iteration=iteration_index,
                essay_text=revised_text,
                feedback=feedback,
                word_count=_count_words(revised_text),
            )
        )
        
        previous_text = revised_text
    
    # Save artifacts if requested
    final_essay_path: Path | None = None
    feedback_path: Path | None = None
    
    if config.save_artifacts:
        # Save final essay
        final_essay_path = output_dir / f"{config.essay_basename}_final.txt"
        final_essay_path.write_text(iterations[-1].essay_text, encoding="utf-8")
        
        # Save feedback markdown
        feedback_path = output_dir / f"{config.essay_basename}_feedback.md"
        feedback_content = _build_feedback_markdown(
            topic=topic,
            iterations=iterations,
            essay_basename=config.essay_basename,
        )
        feedback_path.write_text(feedback_content, encoding="utf-8")
        
        # Save each iteration as separate files
        for iteration in iterations:
            iteration_path = output_dir / f"{config.essay_basename}_v{iteration.iteration}.txt"
            iteration_path.write_text(iteration.essay_text, encoding="utf-8")
    
    return WorkflowArtifacts(
        topic=topic,
        iterations=iterations,
        final_essay_path=final_essay_path,
        feedback_path=feedback_path,
    )
