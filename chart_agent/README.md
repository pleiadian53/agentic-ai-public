# Chart Agent - Intelligent Data Visualization

An agentic system for automated chart generation and refinement, combining **code-as-plan** flexibility with **reflection-based** quality improvement.

## üéØ Current Status

**‚úÖ Core Features Implemented:**
- Code-as-plan pattern for flexible chart generation
- Reflection pattern for iterative quality improvement (in examples)
- Multiple data sources (CSV, SQLite, DuckDB, DataFrame, Excel)
- Model management with dynamic recommendations (GPT-5 ready!)
- Utility functions for model selection, code validation, and execution
- Domain-specific example: Genomic splice site analysis
- **üÜï FastAPI REST API Service** - Production-ready web service with Swagger UI
- **üÜï Human-in-the-loop workflow** - Review code before execution
- **üÜï Multi-format output** - PDF, PNG chart generation

**üìù In Development:**
- Standalone reflection module
- Sandboxed execution environment
- General-purpose CLI
- Comprehensive test suite
- Frontend integrations (React, Streamlit)

## Overview

The Chart Agent generates high-quality visualizations from datasets using a two-phase workflow:

1. **Generation Phase** (Code-as-Plan)
   - LLM analyzes dataset and user requirements
   - Generates Python plotting code (matplotlib/seaborn/plotly)
   - Code is immediately executable with provided data

2. **Reflection Phase** (Critique & Refine) - *Optional*
   - LLM critiques the generated chart code
   - Identifies issues (clarity, accuracy, aesthetics, domain relevance)
   - Generates improved version based on feedback
   - Iterates until quality threshold met or max iterations reached

## Features

- **Flexible Generation:** Code-as-plan allows complex, adaptive chart logic
- **Quality Assurance:** Optional reflection ensures charts meet best practices
- **Multi-Format Support:** CSV, SQLite, DuckDB, pandas DataFrames, Excel
- **Multiple Libraries:** matplotlib, seaborn, plotly (auto-selected based on chart type)
- **Model Selection:** Dynamic recommendations for GPT-4o-mini (default), GPT-5, Codex
- **Configurable Reflection:** Control iteration depth, model selection, and critique criteria
- **Utility Functions:** Model listing, code validation, HTML display, execution helpers

## Quick Start

### Option 1: REST API Service (Recommended for Production)

The Chart Agent provides a production-ready FastAPI service with Swagger UI for easy testing and integration.

**Start the service:**
```bash
cd chart_agent/server
mamba run -n agentic-ai python manage.py start
```

**Access the API:**
- **Swagger UI**: http://localhost:8003/docs
- **API Base**: http://localhost:8003
- **Health Check**: http://localhost:8003/health

**Quick API Example:**
```bash
curl -X POST http://localhost:8003/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_path": "data/splice_sites_enhanced.tsv",
    "question": "Show the top 20 genes with the most splice sites",
    "model": "gpt-4o-mini"
  }'
```

**Full Documentation:**
- [Quick Start Guide](server/QUICKSTART.md)
- [Service Management](server/SERVICE_MANAGEMENT.md)
- [Integration Guide](server/INTEGRATION.md)
- [Frontend Tutorials](docs/frontend/) - React, Streamlit, Swagger UI

### Option 2: Python Library (For Direct Integration)

#### Prerequisites

1. **Install dependencies:**
   ```bash
   cd /path/to/agentic-ai-lab
   pip install -e .
   ```

2. **Set up OpenAI API key:**
   ```bash
   export OPENAI_API_KEY='your-api-key-here'
   ```
   
   Or add to `.env` file in repository root:
   ```
   OPENAI_API_KEY=your-api-key-here
   ```
   
   Get your API key from: https://platform.openai.com/api-keys

### Basic Usage

```python
from openai import OpenAI
from chart_agent import chart_agent, CSVDataset

client = OpenAI()
dataset = CSVDataset("data/coffee_sales.csv")

result = chart_agent(
    dataset=dataset,
    user_request="Create a bar chart showing total sales by product category",
    client=client,
    use_reflection=True,
    max_reflections=2
)

if result["success"]:
    result["final_chart"].show()  # Display chart
    print(f"Iterations: {result['reflection_count']}")
```

### CLI Usage

```bash
# Generate chart with reflection
run-chart-agent \
    --data data/coffee_sales.csv \
    --prompt "Show monthly sales trends" \
    --reflect \
    --output charts/sales_trend.png

# Quick generation without reflection
run-chart-agent \
    --data data/coffee_sales.csv \
    --prompt "Bar chart of top 10 products" \
    --no-reflect
```

## Package Structure

```
chart_agent/
‚îú‚îÄ‚îÄ __init__.py              # ‚úÖ Package initialization with exports
‚îú‚îÄ‚îÄ data_access.py           # ‚úÖ Dataset abstraction layer (CSV, SQL, DuckDB, etc.)
‚îú‚îÄ‚îÄ planning.py              # ‚úÖ LLM-based chart code generation
‚îú‚îÄ‚îÄ utils.py                 # ‚úÖ Utility functions (model listing, display, execution, validation)
‚îú‚îÄ‚îÄ server/                  # ‚úÖ FastAPI REST API Service
‚îÇ   ‚îú‚îÄ‚îÄ chart_service.py         # ‚úÖ Main FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py               # ‚úÖ Pydantic request/response models
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # ‚úÖ Centralized configuration
‚îÇ   ‚îú‚îÄ‚îÄ manage.py                # ‚úÖ Service management CLI
‚îÇ   ‚îú‚îÄ‚îÄ stop_service.sh          # ‚úÖ Graceful shutdown script
‚îÇ   ‚îú‚îÄ‚îÄ test_client.py           # ‚úÖ Python API client example
‚îÇ   ‚îú‚îÄ‚îÄ test_analyze.py          # ‚úÖ Direct endpoint testing
‚îÇ   ‚îú‚îÄ‚îÄ test_http.py             # ‚úÖ HTTP request testing
‚îÇ   ‚îú‚îÄ‚îÄ test_full_workflow.py    # ‚úÖ Complete workflow demo
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md            # ‚úÖ Getting started guide
‚îÇ   ‚îú‚îÄ‚îÄ SERVICE_MANAGEMENT.md    # ‚úÖ Deployment & operations
‚îÇ   ‚îú‚îÄ‚îÄ INTEGRATION.md           # ‚úÖ Integration patterns
‚îÇ   ‚îî‚îÄ‚îÄ SUMMARY.md               # ‚úÖ Architecture overview
‚îú‚îÄ‚îÄ examples/                # ‚úÖ Usage examples and demos
‚îÇ   ‚îú‚îÄ‚îÄ analyze_splice_sites.py  # ‚úÖ Domain-specific driver with reflection pattern
‚îÇ   ‚îú‚îÄ‚îÄ utils_demo.py            # ‚úÖ Utility functions demo
‚îÇ   ‚îî‚îÄ‚îÄ README.md                # ‚úÖ Examples documentation
‚îú‚îÄ‚îÄ data/                    # ‚úÖ Data storage
‚îÇ   ‚îú‚îÄ‚îÄ llm/                     # ‚úÖ LLM model information
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ available_models.json  # ‚úÖ Saved model list with recommendations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md              # ‚úÖ Model documentation
‚îÇ   ‚îî‚îÄ‚îÄ mane/                    # ‚úÖ Genomic data
‚îÇ       ‚îî‚îÄ‚îÄ GRCh38/
‚îÇ           ‚îî‚îÄ‚îÄ splice_sites_enhanced.tsv
‚îú‚îÄ‚îÄ docs/                    # ‚úÖ Frontend & Integration Tutorials
‚îÇ   ‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SWAGGER_UI.md        # ‚úÖ Swagger UI guide
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ REACT.md             # ‚úÖ React integration tutorial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ STREAMLIT.md         # ‚úÖ Streamlit app tutorial
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CURL.md              # ‚úÖ Command-line usage
‚îÇ   ‚îî‚îÄ‚îÄ ARCHITECTURE.md          # ‚úÖ System design & patterns
‚îî‚îÄ‚îÄ tests/                   # üß™ Test suite (planned)
    ‚îú‚îÄ‚îÄ test_data_access.py
    ‚îú‚îÄ‚îÄ test_planning.py
    ‚îî‚îÄ‚îÄ test_utils.py
```

### Implementation Status

**‚úÖ Implemented:**
- **Core functionality**: Data access, planning, utilities
- **Code-as-plan pattern**: LLM generates executable visualization code
- **Reflection pattern**: Implemented in `analyze_splice_sites.py` example
- **Model management**: Save/load model lists, dynamic recommendations
- **Multiple data sources**: CSV, SQLite, DuckDB, DataFrame, Excel
- **Utility functions**: Model listing, HTML display, code execution, validation

**üìù Planned (Future Work):**
- **`execution.py`**: Sandboxed code execution environment
- **`reflection.py`**: Standalone reflection module (currently in examples)
- **`agent.py`**: Main orchestration with full agentic loop
- **`cli.py`**: Command-line interface for general use
- **Comprehensive test suite**: Unit and integration tests

**Note**: Reflection functionality is fully implemented in the `analyze_splice_sites.py` example, demonstrating the pattern. A standalone `reflection.py` module would generalize this for reuse across different domains.

## Workflow

### Phase 1: Generation (Code-as-Plan)

```
User Request + Dataset
        ‚Üì
[LLM Planning]
  - Analyze dataset schema
  - Understand user intent
  - Select appropriate chart type
  - Generate plotting code
        ‚Üì
[Sandbox Execution]
  - Execute code safely
  - Capture chart object
  - Handle errors
        ‚Üì
Initial Chart
```

### Phase 2: Reflection (Optional)

```
Initial Chart + Code
        ‚Üì
[LLM Critique]
  - Evaluate clarity
  - Check accuracy
  - Assess aesthetics
  - Identify improvements
        ‚Üì
[LLM Refinement]
  - Generate improved code
  - Address critique points
        ‚Üì
[Sandbox Execution]
  - Execute refined code
        ‚Üì
Improved Chart
        ‚Üì
[Quality Check]
  - Meets threshold? ‚Üí Done
  - Needs work? ‚Üí Iterate (max N times)
```

## Example Scenarios

### Sales Analysis

```python
result = chart_agent(
    dataset=CSVDataset("coffee_sales.csv"),
    user_request="Show quarterly sales trends with moving average",
    use_reflection=True
)
```

### Customer Segmentation

```python
result = chart_agent(
    dataset=SQLiteDataset("customers.db", "SELECT age, income, segment FROM customers"),
    user_request="Create a scatter plot showing customer segments by age and income",
    use_reflection=True
)
```

### Multi-Panel Dashboard

```python
result = chart_agent(
    dataset=df,  # pandas DataFrame
    user_request="Create a 2x2 dashboard: sales by region, top products, monthly trends, and category breakdown",
    use_reflection=True,
    max_reflections=3
)
```

## Configuration

### Reflection Settings

```python
result = chart_agent(
    dataset=dataset,
    user_request=prompt,
    use_reflection=True,
    max_reflections=3,          # Max iteration count
    reflection_criteria=[        # Custom critique criteria
        "clarity",
        "accuracy",
        "aesthetics",
        "accessibility"
    ],
    quality_threshold=0.8        # Stop if quality score > threshold
)
```

### Library Selection

```python
result = chart_agent(
    dataset=dataset,
    user_request=prompt,
    preferred_library="plotly",  # Force specific library
    # Options: "matplotlib", "seaborn", "plotly", "auto"
)
```

## Comparison with Existing Workflows

| Feature | chartgen | reflection/chart_workflow | chart_agent (New) |
|---------|----------|--------------------------|-------------------|
| **Code Generation** | ‚úÖ Notebook-based | ‚úÖ Module-based | ‚úÖ Production-ready |
| **Reflection** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (configurable) |
| **Data Formats** | CSV only | CSV only | CSV, SQLite, DataFrame |
| **Sandboxing** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes |
| **Error Handling** | Basic | Good | Comprehensive |
| **Reusability** | Low | Medium | High |
| **CLI** | ‚ùå No | ‚ùå No | ‚úÖ Yes |
| **Tests** | ‚ùå No | ‚ùå No | ‚úÖ Yes |

## Advanced Usage

### Custom Critique Criteria

```python
from chart_agent import chart_agent, CritiqueCriteria

custom_criteria = CritiqueCriteria(
    clarity="Are labels clear and readable?",
    accuracy="Does the chart accurately represent the data?",
    aesthetics="Is the color scheme professional?",
    accessibility="Is the chart accessible to colorblind users?",
    domain_specific="Does it follow financial reporting standards?"
)

result = chart_agent(
    dataset=dataset,
    user_request=prompt,
    critique_criteria=custom_criteria
)
```

### Streaming Reflection

```python
for iteration in chart_agent_stream(dataset, prompt):
    print(f"Iteration {iteration['count']}")
    print(f"Critique: {iteration['critique']}")
    iteration['chart'].show()
```

## Design Patterns Used

### 1. Code-as-Plan (from customer_service)
- **Flexibility:** LLM generates arbitrary plotting logic
- **Adaptability:** Can handle complex, multi-step visualizations
- **Power:** Full Python/matplotlib/seaborn/plotly capabilities

### 2. Reflection (from chart_workflow)
- **Quality Assurance:** Iterative improvement
- **Best Practices:** Enforces visualization principles
- **Error Recovery:** Fixes issues through critique

### 3. Data Abstraction
- **Unified Interface:** Works with CSV, SQLite, DataFrames
- **Schema Detection:** Automatic column type inference
- **Lazy Loading:** Efficient memory usage

## Next Steps

- See `docs/USAGE.md` for detailed API reference
- See `docs/EXAMPLES.md` for more examples
- Try the CLI: `run-chart-agent --help`
- Extend with custom chart types or libraries

## License

Part of the agentic-ai-lab repository.
